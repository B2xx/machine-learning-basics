{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VG4BPHr0LZHU"
   },
   "outputs": [],
   "source": [
    "!pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S8LVfH2MK4zy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed mean: [0.6204590201377869, 0.5430712699890137, 0.44747450947761536]\n",
      "Computed std: [0.1726725846529007, 0.1666186898946762, 0.1685081124305725]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CustomHFDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None, test_flag=False):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "        self.test_flag = test_flag\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.hf_dataset[idx]\n",
    "        image = example['image']\n",
    "        label = example['label']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.test_flag:\n",
    "            return image, example['idx']\n",
    "        else:\n",
    "            return image, label\n",
    "\n",
    "# -------------------------------------------\n",
    "# Load dataset\n",
    "# -------------------------------------------\n",
    "dataset = load_dataset('hmdliu/ACAC-4K')\n",
    "\n",
    "# Compute mean and std of the training set\n",
    "temp_transform = transforms.ToTensor()\n",
    "temp_dataset = CustomHFDataset(dataset['train'], transform=temp_transform, test_flag=False)\n",
    "\n",
    "def compute_mean_std(dset):\n",
    "    loader = DataLoader(dset, batch_size=32, shuffle=False)\n",
    "    mean = 0.0\n",
    "    var = 0.0\n",
    "    total_pixels = 0\n",
    "    for imgs, _ in loader:\n",
    "        # imgs: (B, C, H, W)\n",
    "        imgs = imgs.view(imgs.size(0), imgs.size(1), -1)\n",
    "        batch_pixels = imgs.size(0)*imgs.size(2)\n",
    "        mean += imgs.sum(dim=[0,2])\n",
    "        var += (imgs**2).sum(dim=[0,2])\n",
    "        total_pixels += batch_pixels\n",
    "    mean = mean / total_pixels\n",
    "    var = var / total_pixels\n",
    "    std = torch.sqrt(var - mean**2)\n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "mean, std = compute_mean_std(temp_dataset)\n",
    "\n",
    "print(\"Computed mean:\", mean)\n",
    "print(\"Computed std:\", std)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Define transforms\n",
    "# -------------------------------------------\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Stronger augmentations + Mixup or CutMix will be handled in training loop\n",
    "train_augment = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(512, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# -------------------------------------------\n",
    "# Create base dataset and split train/val\n",
    "# -------------------------------------------\n",
    "train_dataset_raw = CustomHFDataset(dataset['train'], transform=base_transform, test_flag=False)\n",
    "test_dataset = CustomHFDataset(dataset['test'], transform=val_transform, test_flag=True)\n",
    "\n",
    "num_train = len(train_dataset_raw)\n",
    "indices = list(range(num_train))\n",
    "random.shuffle(indices)\n",
    "val_ratio = 0.1\n",
    "split = int(val_ratio * num_train)\n",
    "val_indices = indices[:split]\n",
    "train_indices = indices[split:]\n",
    "\n",
    "val_dataset = Subset(train_dataset_raw, val_indices)\n",
    "\n",
    "all_labels = [train_dataset_raw[i][1] for i in range(len(train_dataset_raw))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xrFGk5IYLprO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Binary Model] Epoch 1/15, Loss: 0.4646\n",
      "[Binary Model] Epoch 2/15, Loss: 0.3857\n",
      "[Binary Model] Epoch 3/15, Loss: 0.3700\n",
      "[Binary Model] Epoch 4/15, Loss: 0.3364\n",
      "[Binary Model] Epoch 5/15, Loss: 0.3196\n",
      "[Binary Model] Epoch 6/15, Loss: 0.3350\n",
      "[Binary Model] Epoch 7/15, Loss: 0.3587\n",
      "[Binary Model] Epoch 8/15, Loss: 0.3005\n",
      "[Binary Model] Epoch 9/15, Loss: 0.2986\n",
      "[Binary Model] Epoch 10/15, Loss: 0.2448\n",
      "[Binary Model] Epoch 11/15, Loss: 0.2214\n",
      "[Binary Model] Epoch 12/15, Loss: 0.2370\n",
      "[Binary Model] Epoch 13/15, Loss: 0.2294\n",
      "[Binary Model] Epoch 14/15, Loss: 0.1986\n",
      "[Binary Model] Epoch 15/15, Loss: 0.2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\182318939.py:131: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\182318939.py:179: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Wrong image height! Expected 224 but got 512!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 186\u001b[0m\n\u001b[0;32m    184\u001b[0m         loss \u001b[38;5;241m=\u001b[39m mixup_criterion(criterion, logits, y_a, y_b, lam)\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m         logits \u001b[38;5;241m=\u001b[39m vit_model(img)\n\u001b[0;32m    187\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(logits, lb)\n\u001b[0;32m    188\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\models\\vision_transformer.py:291\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;66;03m# Reshape and permute the input tensor\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_input(x)\n\u001b[0;32m    292\u001b[0m     n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# Expand the class token to the full batch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\models\\vision_transformer.py:271\u001b[0m, in \u001b[0;36mVisionTransformer._process_input\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    269\u001b[0m n, c, h, w \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    270\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size\n\u001b[1;32m--> 271\u001b[0m torch\u001b[38;5;241m.\u001b[39m_assert(h \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong image height! Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    272\u001b[0m torch\u001b[38;5;241m.\u001b[39m_assert(w \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong image width! Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m n_h \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m p\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:2040\u001b[0m, in \u001b[0;36m_assert\u001b[1;34m(condition, message)\u001b[0m\n\u001b[0;32m   2034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(condition) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;129;01mand\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhas_torch_function(\n\u001b[0;32m   2035\u001b[0m     (condition,)\n\u001b[0;32m   2036\u001b[0m ):\n\u001b[0;32m   2037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhandle_torch_function(\n\u001b[0;32m   2038\u001b[0m         _assert, (condition,), condition, message\n\u001b[0;32m   2039\u001b[0m     )\n\u001b[1;32m-> 2040\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m condition, message\n",
      "\u001b[1;31mAssertionError\u001b[0m: Wrong image height! Expected 224 but got 512!"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Stage 1: Binary AI vs Non-AI classification for initial label correction\n",
    "# -------------------------------------------\n",
    "ai_indices = [i for i, l in enumerate(all_labels) if l == 5]\n",
    "non_ai_indices = [i for i, l in enumerate(all_labels) if l in [0,1,2,3,4]]\n",
    "\n",
    "# Balance binary training set\n",
    "sample_size = min(len(ai_indices), len(non_ai_indices))\n",
    "random.shuffle(non_ai_indices)\n",
    "balanced_non_ai_indices = non_ai_indices[:sample_size]\n",
    "binary_train_indices = ai_indices + balanced_non_ai_indices\n",
    "random.shuffle(binary_train_indices)\n",
    "\n",
    "class BinaryAIDataset(Dataset):\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[self.indices[idx]]\n",
    "        bin_label = 1 if label == 5 else 0\n",
    "        return img, bin_label\n",
    "\n",
    "binary_train_dataset = BinaryAIDataset(train_dataset_raw, binary_train_indices)\n",
    "binary_train_loader = DataLoader(binary_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# A stronger binary model, say a wider resnet (no pretrained)\n",
    "binary_model = models.resnet50(pretrained=False)\n",
    "binary_model.fc = nn.Linear(binary_model.fc.in_features, 2)\n",
    "binary_model = binary_model.to(device)\n",
    "\n",
    "criterion_bin = nn.CrossEntropyLoss()\n",
    "optimizer_bin = optim.Adam(binary_model.parameters(), lr=1e-4)\n",
    "epochs_bin = 10\n",
    "\n",
    "binary_model.train()\n",
    "for epoch in range(epochs_bin):\n",
    "    total_loss = 0.0\n",
    "    for imgs, lbs in binary_train_loader:\n",
    "        imgs, lbs = imgs.to(device), lbs.to(device)\n",
    "        optimizer_bin.zero_grad()\n",
    "        logits = binary_model(imgs)\n",
    "        loss = criterion_bin(logits, lbs)\n",
    "        loss.backward()\n",
    "        optimizer_bin.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"[Binary Model] Epoch {epoch+1}/{epochs_bin}, Loss: {total_loss/len(binary_train_loader):.4f}\")\n",
    "\n",
    "# Inference for AI probabilities\n",
    "binary_model.eval()\n",
    "ai_probs = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(train_dataset_raw)):\n",
    "        img, lb = train_dataset_raw[i]\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        logit = binary_model(img)\n",
    "        prob = F.softmax(logit, dim=1)[0,1].item()\n",
    "        ai_probs.append(prob)\n",
    "\n",
    "# Initial threshold-based correction\n",
    "threshold = 0.5\n",
    "corrected_labels = deepcopy(all_labels)\n",
    "for i in range(len(corrected_labels)):\n",
    "    if corrected_labels[i] != 5 and ai_probs[i] > threshold:\n",
    "        corrected_labels[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Prepare the corrected dataset for the main classifier\n",
    "# -------------------------------------------\n",
    "class CorrectedDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, corrected_labels, transform=None):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.corrected_labels = corrected_labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.hf_dataset[idx]\n",
    "        image = example['image']\n",
    "        label = self.corrected_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "corrected_train_dataset = CorrectedDataset(dataset['train'], corrected_labels, transform=train_augment)\n",
    "corrected_val_dataset = CorrectedDataset(dataset['train'], corrected_labels, transform=val_transform)\n",
    "\n",
    "train_dataset_final = Subset(corrected_train_dataset, train_indices)\n",
    "val_dataset_final = Subset(corrected_val_dataset, val_indices)\n",
    "\n",
    "# Compute class weights for WeightedRandomSampler due to imbalance\n",
    "final_labels_train = [corrected_labels[i] for i in train_indices]\n",
    "class_counts = np.bincount(final_labels_train, minlength=6)\n",
    "class_weights = 1.0 / (class_counts + 1e-6)\n",
    "weights = [class_weights[l] for l in final_labels_train]\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset_final, batch_size=16, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset_final, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augment = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(512, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:27: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.7000, Acc: 0.5062, F1_non_AI: 0.3699, F1_AI: 0.5263, WM: 0.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 1.4879, Acc: 0.5219, F1_non_AI: 0.4236, F1_AI: 0.5417, WM: 0.4957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 1.3883, Acc: 0.4656, F1_non_AI: 0.3811, F1_AI: 0.3902, WM: 0.4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 1.3516, Acc: 0.4156, F1_non_AI: 0.3656, F1_AI: 0.4878, WM: 0.4230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 1.2985, Acc: 0.5344, F1_non_AI: 0.4844, F1_AI: 0.5424, WM: 0.5204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 1.2462, Acc: 0.5531, F1_non_AI: 0.4953, F1_AI: 0.4878, WM: 0.5121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Loss: 1.2177, Acc: 0.5469, F1_non_AI: 0.5054, F1_AI: 0.5417, WM: 0.5313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Loss: 1.1870, Acc: 0.5719, F1_non_AI: 0.5401, F1_AI: 0.5778, WM: 0.5632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Loss: 1.1553, Acc: 0.5969, F1_non_AI: 0.5572, F1_AI: 0.5000, WM: 0.5513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Loss: 1.1287, Acc: 0.5844, F1_non_AI: 0.5519, F1_AI: 0.5532, WM: 0.5632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Loss: 1.1144, Acc: 0.6062, F1_non_AI: 0.5653, F1_AI: 0.5532, WM: 0.5749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Loss: 1.0883, Acc: 0.6062, F1_non_AI: 0.5598, F1_AI: 0.5532, WM: 0.5731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Loss: 1.0975, Acc: 0.5844, F1_non_AI: 0.5471, F1_AI: 0.4878, WM: 0.5398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Loss: 1.0972, Acc: 0.5469, F1_non_AI: 0.5303, F1_AI: 0.5532, WM: 0.5434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Loss: 1.2030, Acc: 0.5906, F1_non_AI: 0.5310, F1_AI: 0.6222, WM: 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Loss: 1.1647, Acc: 0.5344, F1_non_AI: 0.4952, F1_AI: 0.5574, WM: 0.5290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Loss: 1.1775, Acc: 0.5687, F1_non_AI: 0.5019, F1_AI: 0.5532, WM: 0.5413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Loss: 1.2212, Acc: 0.6031, F1_non_AI: 0.5413, F1_AI: 0.5926, WM: 0.5790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Loss: 1.1951, Acc: 0.5750, F1_non_AI: 0.4956, F1_AI: 0.5714, WM: 0.5474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Loss: 1.2120, Acc: 0.5938, F1_non_AI: 0.5360, F1_AI: 0.6122, WM: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 1/20, Loss: 1.1845, Acc: 0.5563, F1_non_AI: 0.4959, F1_AI: 0.5455, WM: 0.5325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 2/20, Loss: 1.1729, Acc: 0.6156, F1_non_AI: 0.5672, F1_AI: 0.6667, WM: 0.6165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 3/20, Loss: 1.1066, Acc: 0.5500, F1_non_AI: 0.5296, F1_AI: 0.5909, WM: 0.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 4/20, Loss: 1.0790, Acc: 0.5656, F1_non_AI: 0.5087, F1_AI: 0.5581, WM: 0.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 5/20, Loss: 1.0261, Acc: 0.5813, F1_non_AI: 0.5865, F1_AI: 0.5500, WM: 0.5726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 6/20, Loss: 0.9913, Acc: 0.6344, F1_non_AI: 0.5959, F1_AI: 0.5714, WM: 0.6006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 7/20, Loss: 0.9863, Acc: 0.6281, F1_non_AI: 0.5773, F1_AI: 0.6222, WM: 0.6092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 8/20, Loss: 0.9606, Acc: 0.6281, F1_non_AI: 0.5882, F1_AI: 0.6047, WM: 0.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 9/20, Loss: 0.9407, Acc: 0.6094, F1_non_AI: 0.5766, F1_AI: 0.5581, WM: 0.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 10/20, Loss: 0.9414, Acc: 0.6562, F1_non_AI: 0.6159, F1_AI: 0.6047, WM: 0.6256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 11/20, Loss: 0.8712, Acc: 0.6625, F1_non_AI: 0.6183, F1_AI: 0.6667, WM: 0.6491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 12/20, Loss: 0.9480, Acc: 0.6719, F1_non_AI: 0.6132, F1_AI: 0.6957, WM: 0.6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 13/20, Loss: 0.9295, Acc: 0.6969, F1_non_AI: 0.6382, F1_AI: 0.7111, WM: 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 14/20, Loss: 0.9402, Acc: 0.6719, F1_non_AI: 0.6144, F1_AI: 0.5714, WM: 0.6192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 15/20, Loss: 0.9649, Acc: 0.6625, F1_non_AI: 0.6405, F1_AI: 0.6341, WM: 0.6457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 16/20, Loss: 0.9664, Acc: 0.6406, F1_non_AI: 0.5879, F1_AI: 0.6047, WM: 0.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 17/20, Loss: 0.9650, Acc: 0.6156, F1_non_AI: 0.5583, F1_AI: 0.5581, WM: 0.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 18/20, Loss: 0.9913, Acc: 0.6156, F1_non_AI: 0.5611, F1_AI: 0.6222, WM: 0.5997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 19/20, Loss: 1.0358, Acc: 0.6562, F1_non_AI: 0.6006, F1_AI: 0.5714, WM: 0.6094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuol\\AppData\\Local\\Temp\\ipykernel_20784\\2921258562.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\zhuol\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Refined] Epoch 20/20, Loss: 0.9989, Acc: 0.5844, F1_non_AI: 0.5524, F1_AI: 0.6809, WM: 0.6059\n",
      "Submission saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Define a Vision Transformer model from scratch\n",
    "# -------------------------------------------\n",
    "vit_model = models.vit_b_16(weights=None,image_size=512)  # no pretrained weights\n",
    "num_features = vit_model.heads[0].in_features\n",
    "vit_model.heads[0] = nn.Linear(num_features,6)\n",
    "vit_model = vit_model.to(device)\n",
    "\n",
    "# Label smoothing\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "    def forward(self, x, target):\n",
    "        log_probs = F.log_softmax(x, dim=-1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(log_probs)\n",
    "            true_dist.fill_(self.smoothing / (x.size(-1) - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))\n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
    "optimizer = optim.AdamW(vit_model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Mixup function\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for img, lb in loader:\n",
    "            img, lb = img.to(device), lb.to(device)\n",
    "            out = model(img)\n",
    "            pred = out.argmax(dim=1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "            trues.extend(lb.cpu().numpy())\n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)\n",
    "    accuracy = (preds == trues).mean()\n",
    "    f1_scores = f1_score(trues, preds, labels=range(6), average=None, zero_division=0)\n",
    "    f1_non_ai = np.mean(f1_scores[:5])\n",
    "    f1_ai = f1_scores[5]\n",
    "    weighted_metric = (accuracy + f1_non_ai + f1_ai) / 3\n",
    "    return accuracy, f1_non_ai, f1_ai, weighted_metric\n",
    "\n",
    "# -------------------------------------------\n",
    "# Train final model (first round)\n",
    "# -------------------------------------------\n",
    "epochs = 20\n",
    "best_wm = 0.0\n",
    "for epoch in range(epochs):\n",
    "    vit_model.train()\n",
    "    total_loss = 0\n",
    "    for img, lb in train_loader:\n",
    "        img, lb = img.to(device), lb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            if random.random() < 0.5:\n",
    "                # apply mixup\n",
    "                img, y_a, y_b, lam = mixup_data(img, lb)\n",
    "                logits = vit_model(img)\n",
    "                loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
    "            else:\n",
    "                logits = vit_model(img)\n",
    "                loss = criterion(logits, lb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "\n",
    "    acc, f1_non_ai, f1_ai, wm = evaluate(vit_model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Acc: {acc:.4f}, \"\n",
    "          f\"F1_non_AI: {f1_non_ai:.4f}, F1_AI: {f1_ai:.4f}, WM: {wm:.4f}\")\n",
    "    if wm > best_wm:\n",
    "        best_wm = wm\n",
    "        best_model_state = deepcopy(vit_model.state_dict())\n",
    "\n",
    "# Load best model from first training round\n",
    "vit_model.load_state_dict(best_model_state)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Additional Noise Refinement Step:\n",
    "# Use the trained model to re-check labels. If a sample strongly disagrees, correct again.\n",
    "# For example, if model predicts AI with probability > 0.9 but label is not AI, relabel as AI.\n",
    "# -------------------------------------------\n",
    "vit_model.eval()\n",
    "second_ai_probs = []\n",
    "with torch.no_grad():\n",
    "    train_loader_for_check = DataLoader(train_dataset_raw, batch_size=32, shuffle=False)\n",
    "    # Note: The dataset here returns original images and labels (before transform),\n",
    "    # so we apply the base_transform to images again\n",
    "    # We'll just do a quick inline transform\n",
    "    for imgs, lbs in train_loader_for_check:\n",
    "        imgs = imgs.to(device)\n",
    "        # apply base_transform again is tricky here, we already have in train_dataset_raw,\n",
    "        # but it's already transformed. Let's assume train_dataset_raw is with base_transform.\n",
    "        # If not, we need to re-apply. We'll trust that train_dataset_raw is with base_transform done.\n",
    "        out = vit_model(imgs)\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        second_ai_probs.extend(probs[:,5].cpu().tolist())\n",
    "\n",
    "new_corrected_labels = deepcopy(corrected_labels)\n",
    "for idx, label in enumerate(new_corrected_labels):\n",
    "    if label != 5 and second_ai_probs[idx] > 0.9:\n",
    "        new_corrected_labels[idx] = 5\n",
    "\n",
    "# Retrain with second round corrected labels\n",
    "final_corrected_train_dataset = CorrectedDataset(dataset['train'], new_corrected_labels, transform=train_augment)\n",
    "final_corrected_val_dataset = CorrectedDataset(dataset['train'], new_corrected_labels, transform=val_transform)\n",
    "final_train_dataset = Subset(final_corrected_train_dataset, train_indices)\n",
    "final_val_dataset = Subset(final_corrected_val_dataset, val_indices)\n",
    "\n",
    "final_labels_train = [new_corrected_labels[i] for i in train_indices]\n",
    "class_counts = np.bincount(final_labels_train, minlength=6)\n",
    "class_weights = 1.0 / (class_counts + 1e-6)\n",
    "weights = [class_weights[l] for l in final_labels_train]\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "final_train_loader = DataLoader(final_train_dataset, batch_size=16, sampler=sampler)\n",
    "final_val_loader = DataLoader(final_val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Reinitialize and train again (fresh model or re-use the improved model)\n",
    "# Let's reuse the improved model weights to save time\n",
    "vit_model.load_state_dict(best_model_state)\n",
    "optimizer = optim.AdamW(vit_model.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "best_wm = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    vit_model.train()\n",
    "    total_loss = 0\n",
    "    for img, lb in final_train_loader:\n",
    "        img, lb = img.to(device), lb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            if random.random() < 0.5:\n",
    "                img, y_a, y_b, lam = mixup_data(img, lb)\n",
    "                logits = vit_model(img)\n",
    "                loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
    "            else:\n",
    "                logits = vit_model(img)\n",
    "                loss = criterion(logits, lb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "\n",
    "    acc, f1_non_ai, f1_ai, wm = evaluate(vit_model, final_val_loader)\n",
    "    print(f\"[Refined] Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(final_train_loader):.4f}, \"\n",
    "          f\"Acc: {acc:.4f}, F1_non_AI: {f1_non_ai:.4f}, F1_AI: {f1_ai:.4f}, WM: {wm:.4f}\")\n",
    "    if wm > best_wm:\n",
    "        best_wm = wm\n",
    "        best_model_state = deepcopy(vit_model.state_dict())\n",
    "\n",
    "vit_model.load_state_dict(best_model_state)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Inference on Test set\n",
    "# -------------------------------------------\n",
    "vit_model.eval()\n",
    "test_preds = []\n",
    "test_indices = []\n",
    "with torch.no_grad():\n",
    "    for img, idxs in test_loader:\n",
    "        img = img.to(device)\n",
    "        out = vit_model(img)\n",
    "        pred = out.argmax(dim=1).cpu().numpy().tolist()\n",
    "        test_preds.extend(pred)\n",
    "        test_indices.extend(idxs.numpy().tolist())\n",
    "\n",
    "output_path = \"submission.csv\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\"idx,predicted_label\\n\")\n",
    "    for i, p in zip(test_indices, test_preds):\n",
    "        f.write(f\"{i},{p}\\n\")\n",
    "\n",
    "print(f\"Submission saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "vit_model = models.vit_b_16(weights=None,image_size=512)  # no pretrained weights\n",
    "num_features = vit_model.heads[0].in_features\n",
    "vit_model.heads[0] = nn.Linear(num_features,6)\n",
    "vit_model.load_state_dict(torch.load(\"vit_model.pth\", map_location=device))\n",
    "vit_model.eval()# Make sure the model is in evaluation mode\n",
    "\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "all_probs = []  # To store softmax probabilities\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, lb in val_loader:\n",
    "        img = img.to(device)\n",
    "        lb = lb.to(device)\n",
    "        outputs = vit_model(img)  # Raw logits\n",
    "        probs = F.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "        \n",
    "        preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "        labels = lb.cpu().numpy()\n",
    "        probs_np = probs.cpu().numpy()  # Convert probabilities to numpy array\n",
    "        \n",
    "        all_preds.extend(preds)\n",
    "        all_trues.extend(labels)\n",
    "        all_probs.extend(probs_np)  # Each entry in all_probs is a list of probabilities for 6 classes\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_trues = np.array(all_trues)\n",
    "all_probs = np.array(all_probs)  # Shape: (num_samples, 6))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(all_trues, all_preds)\n",
    "acc = accuracy_score(all_trues, all_preds)\n",
    "\n",
    "print(\"Validation Accuracy:\", acc)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Optionally, you can visualize the confusion matrix:\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(6), yticklabels=range(6))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Validation Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification for the threshold for making better prediction for AI images (After Checking Confusion Matrix)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Inference on Test set\n",
    "# -------------------------------------------\n",
    "vit_model = models.vit_b_16(weights=None, image_size=512)  # no pretrained weights\n",
    "num_features = vit_model.heads[0].in_features\n",
    "vit_model.heads[0] = nn.Linear(num_features, 6)\n",
    "vit_model.load_state_dict(torch.load(\"vit_model.pth\", map_location=device))\n",
    "vit_model = vit_model.to(device)\n",
    "vit_model.eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "threshold = 0.53\n",
    "\n",
    "test_indices = []\n",
    "test_top_predictions = []\n",
    "# (top_class, top_class_prob, second_class, second_class_prob)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, idxs in test_loader:\n",
    "        img = img.to(device)\n",
    "        out = vit_model(img)  # shape: (batch, 6)\n",
    "        probs = F.softmax(out, dim=1)  # shape: (batch, 6)\n",
    "\n",
    "        # Get top 2 predictions\n",
    "        top2_values, top2_indices = torch.topk(probs, k=2, dim=1)  \n",
    "        \n",
    "        top2_values = top2_values.cpu().numpy()\n",
    "        top2_indices = top2_indices.cpu().numpy()\n",
    "        idxs = idxs.cpu().numpy()\n",
    "        \n",
    "        for i in range(len(idxs)):\n",
    "            test_indices.append(idxs[i])\n",
    "            test_top_predictions.append((top2_indices[i,0], top2_values[i,0],\n",
    "                                         top2_indices[i,1], top2_values[i,1]))\n",
    "\n",
    "# Apply threshold logic\n",
    "final_predictions = []\n",
    "for (c1, p1, c2, p2) in test_top_predictions:\n",
    "    if c1 == 5:\n",
    "        if p1 >= threshold:\n",
    "            # Remain class 5\n",
    "            final_predictions.append(5)\n",
    "        else:\n",
    "            # Assign second-best class\n",
    "            final_predictions.append(c2)\n",
    "    else:\n",
    "        # Just assign top class\n",
    "        final_predictions.append(c1)\n",
    "\n",
    "# Save results to submission file\n",
    "output_path = \"submission.csv\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\"idx,predicted_label\\n\")\n",
    "    for idx, pred in zip(test_indices, final_predictions):\n",
    "        f.write(f\"{idx},{pred}\\n\")\n",
    "\n",
    "print(f\"Submission saved to {output_path}\")\n",
    "print(f\"Threshold used: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved to local\n"
     ]
    }
   ],
   "source": [
    "# Replace 'MyDrive' and 'your-folder' with your actual Drive folders\n",
    "save_path_final = \"vit_model.pth\"\n",
    "save_path_binary = \"final_binary_model.pth\"\n",
    "\n",
    "torch.save(vit_model.state_dict(), save_path_final)\n",
    "torch.save(binary_model.state_dict(), save_path_binary)\n",
    "\n",
    "print(\"Models saved to local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary model dowload!\n"
     ]
    }
   ],
   "source": [
    "save_path_binary = \"final_binary_model.pth\"\n",
    "torch.save(binary_model.state_dict(), save_path_binary)\n",
    "print(\"binary model dowload!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN6SAMCP8XKWGkWrXdnDFYw",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
